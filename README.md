# Unsupervised Domain Adaptation for Video Transformers in Action Recognition
This is the official repository for the paper:
<!-- > **[Unsupervised Domain Adaptation for Video Transformers in Action Recognition](TODO)**<br> -->
> **Unsupervised Domain Adaptation for Video Transformers in Action Recognition**<br>
> [Victor G. Turrisi da Costa*](https://scholar.google.com/citations?user=UQctXiEAAAAJ&hl=en&oi=ao), [Giacomo Zara](https://scholar.google.com/citations?user=KvwYqUUAAAAJ&hl=en), [Paolo Rota](https://scholar.google.com/citations?user=K1goGQ4AAAAJ&hl=en), [Thiago Oliveira-Santos](https://scholar.google.com/citations?user=i3R7j_8AAAAJ&hl=en), [Nicu Sebe](https://scholar.google.com/citations?user=tNtjSewAAAAJ&hl=en), [Vittorio Murino](https://scholar.google.com/citations?user=yV3_PTkAAAAJ&hl=en), [Elisa Ricci](https://scholar.google.com/citations?user=xf1T870AAAAJ&hl=en), <br>
> **ICPR 2022 (Oral)**

---

### Better README/documentation will be available soon. Nonetheless, the repository is self-contained and all configs for the experiments are available.

---

### Installation

You can install the required libraries using conda:
```
conda create python=3.8 -n udavt
conda activate udavt
pip3 install -r requirements.txt
```

### How to run

All training scripts are contained in the `bash` folder.


# NEC-Drone data.
The cropped NEC-Drone dataset is available for download from [Google Drive](https://drive.google.com/file/d/1C9vkOUaKr1EthHp8VPGDpCxrx8IgTKr2/view?usp=sharing)